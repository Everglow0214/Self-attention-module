# Self-attention-module
## Homework #1 for EE898 (Advanced Topics in Deep Learning for Robotics and Computer Vision)<br>
Three self-attention modules based on three papers are implemented by PyTorch, which are:<br>
[Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) (`resnet_se.py`),<br>
[CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) (`resnet_cbam.py`), and<br>
[BAM: Bottleneck Attention Module](https://arxiv.org/abs/1807.06514) (`resnet_bam.py`),<br>
with the baseline being `ResNet`, proposed in<br>
[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) (`resnet_base.py`).<br>
